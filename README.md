# Kafka Schema Registry With Spring Boot Demo App

Demo app that demonstrates the use of Kafka, Avro serialization and Schema Registry.

## Review Producer
Exposes HTTP endpoint:
- URL: http://localhost:9000/reviews/v1
- Method: POST
- RequestBody (example): 
```json
{
    "rating": 5,
    "body": "Excellent Product"
}
```
- Headers: X-USER-ID  UUID

After receiving the POST request, Review Producer sends ReviewPlacedEvent to Kafka via
Spring Cloud Stream Kafka Binder. Below is the application.yml of Review Producer.

```yml
spring:
  application:
    name: review-producer
  cloud:
    stream:
      bindings:
        reviewSupplier-out-0:
          destination: ${kafkaprops.reviewPlacedTopic}
          producer:
            use-native-encoding: true
            partition-key-expression: headers['X-PARTITION-KEY']
            partition-count: 3
      kafka:
        binder:
          brokers: localhost:9092
          replication-factor: 1
        bindings:
          reviewSupplier-out-0:
            producer:
              configuration:
                value.serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
                schema.registry.url: http://localhost:8081


kafkaprops:
  reviewPlacedTopic: review.placement.v1
  partitionCount: 3
server:
  port: 9000
```

`schema.registry.url` property specifies the location of Confluent Schema Registry, that handles message schemas in Avro format.

Partition-key-expression is used to send messages to different partitions of the Kafka topic: review.placement.v1
It is used in `KafkaReviewServiceImpl` class when sending message via `StreamBridge`:
```kotlin
    private fun sendMessage(bindingName: String, event: ReviewPlacedEvent, userId: UUID) {
        log.debug("Sending a {} message to {}", event, bindingName)
        val message = MessageBuilder.withPayload(event)
            .setHeader(X_PARTITION_KEY_HEADER, event.reviewId)
            .setHeader(X_USER_ID_HEADER, userId)
            .setHeader(X_SERVICE_ORIGIN_HEADER, serviceUtil.getServiceAddress())
            .build()
        streamBridge.send(bindingName, message)
    }
```

Class ReviewPlacedEvent is auto-generated by Avro generator gradle plugin: `id 'com.github.davidmc24.gradle.plugin.avro' version "1.3.0"`.
Avro schema is specified in src/main/avro directory:
```json
{
  "type": "record",
  "name": "ReviewPlacedEvent",
  "namespace": "ru.aasmc.review",
  "fields": [
    {
      "name": "eventId",
      "type": {
        "type": "string",
        "logicalType": "uuid"
      }
    },
    {
      "name": "reviewId",
      "type": {
        "type": "string",
        "logicalType": "uuid"
      },
      "doc": "Unique identifier of the event in the form of UUID"
    },
    {
      "name": "body",
      "type": "string"
    },
    {
      "name": "rating",
      "type": "int"
    }
  ]
}
```

To generate classes from Avro Schema run the following command:
```shell
cd reviewproducer
./gradlew clean build
```

The generated classes for reviewproducer module are located in the folder: 
reviewproducer/build/generated-main-avro-java

Complete build.gradle of the Review Producer:

```groovy
import org.jetbrains.kotlin.gradle.tasks.KotlinCompile

buildscript {
    repositories {
        gradlePluginPortal()
        maven {
            url = "https://packages.confluent.io/maven/"
        }
        maven {
            url = "https://jitpack.io"
        }
    }
}

plugins {
    id 'org.springframework.boot' version '3.1.5'
    id 'io.spring.dependency-management' version '1.1.3'
    id 'org.jetbrains.kotlin.jvm' version '1.8.22'
    id 'org.jetbrains.kotlin.plugin.spring' version '1.8.22'
    id "com.github.imflog.kafka-schema-registry-gradle-plugin" version "1.6.0"
    id 'com.github.davidmc24.gradle.plugin.avro' version "1.3.0"
}

group = 'ru.aasmc'
version = '0.0.1-SNAPSHOT'

java {
    sourceCompatibility = '17'
}

repositories {
    mavenCentral()
    maven {
        url = "https://packages.confluent.io/maven/"
    }
    maven {
        url = "https://jitpack.io"
    }
}

ext {
    set('springCloudVersion', "2022.0.4")
}

dependencies {
    implementation 'org.springframework.boot:spring-boot-starter-actuator'
    implementation 'org.springframework.boot:spring-boot-starter-web'
    implementation 'com.fasterxml.jackson.module:jackson-module-kotlin'
    implementation 'org.jetbrains.kotlin:kotlin-reflect'
    implementation 'org.springframework.cloud:spring-cloud-starter-stream-kafka'
    implementation("io.confluent:kafka-avro-serializer:5.3.0")
    implementation("org.apache.avro:avro:1.11.0")
    annotationProcessor 'org.springframework.boot:spring-boot-configuration-processor'
    testImplementation 'org.springframework.boot:spring-boot-starter-test'
    testImplementation 'org.springframework.boot:spring-boot-testcontainers'
    testImplementation 'org.springframework.cloud:spring-cloud-stream-test-binder'
    testImplementation 'org.testcontainers:junit-jupiter'
    testImplementation 'org.testcontainers:kafka'
}

dependencyManagement {
    imports {
        mavenBom "org.springframework.cloud:spring-cloud-dependencies:${springCloudVersion}"
    }
}

schemaRegistry {
    url = 'http://localhost:8081'
    quiet = true
    register {
        subject('avro-reviewplaced-value', 'src/main/avro/review-placed.avsc', 'AVRO')
    }
}

tasks.withType(KotlinCompile) {
    kotlinOptions {
        freeCompilerArgs += '-Xjsr305=strict'
        jvmTarget = '17'
    }
}

tasks.named('test') {
    useJUnitPlatform()
}
```

## Review Consumer Service
Consumes messages from Kafka topic: review.placement.v1 via Spring Cloud Stream Kafka Binder.
Below is the Review Consumer application.yml

```yml
server:
  port: 9001

spring:
  application:
    name: review-consumer
  cloud:
    stream:
      bindings:
        consumeReviewPlacedEvent-in-0:
          destination: ${kafkaprops.reviewPlacedTopic}
          group: ${spring.application.name}
          consumer:
            use-native-decoding: true
      kafka:
        binder:
          brokers: localhost:9092
        bindings:
          consumeReviewPlacedEvent-in-0:
            consumer:
              configuration:
                value.deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
                schema.registry.url: http://localhost:8081
                specific.avro.reader: true


kafkaprops:
  reviewPlacedTopic: review.placement.v1
```

`spring.cloud.stream.bindings.consumeReviewPlacedEvent-in-0.group` property is used to organize
all instances of Review Consumer Service into a single consumer group. The topic partitions will be
distributed among the Review Consumer instances.

`specific.avro.reader` property enables consumer to read specific message (ReviewPlacedEvent) and not the generic message.

Complete build.gradle of the Review Consumer:
```groovy
import org.jetbrains.kotlin.gradle.tasks.KotlinCompile

buildscript {
    repositories {
        gradlePluginPortal()
        maven {
            url = "https://packages.confluent.io/maven/"
        }
        maven {
            url = "https://jitpack.io"
        }
    }
}

plugins {
    id 'org.springframework.boot' version '3.1.5'
    id 'io.spring.dependency-management' version '1.1.3'
    id 'org.jetbrains.kotlin.jvm' version '1.8.22'
    id 'org.jetbrains.kotlin.plugin.spring' version '1.8.22'
    id "com.github.imflog.kafka-schema-registry-gradle-plugin" version "1.6.0"
    id 'com.github.davidmc24.gradle.plugin.avro' version "1.3.0"
}

group = 'ru.aasmc'
version = '0.0.1-SNAPSHOT'

java {
    sourceCompatibility = '17'
}

configurations {
    compileOnly {
        extendsFrom annotationProcessor
    }
}

repositories {
    mavenCentral()
    maven {
        url = "https://packages.confluent.io/maven/"
    }
    maven {
        url = "https://jitpack.io"
    }
}

ext {
    set('springCloudVersion', "2022.0.4")
}

dependencies {
    implementation 'org.springframework.boot:spring-boot-starter-actuator'
    implementation 'org.springframework.boot:spring-boot-starter-validation'
    implementation 'org.springframework.boot:spring-boot-starter-web'
    implementation 'com.fasterxml.jackson.module:jackson-module-kotlin'
    implementation 'org.jetbrains.kotlin:kotlin-reflect'
    implementation 'org.springframework.cloud:spring-cloud-starter-stream-kafka'
    implementation("io.confluent:kafka-avro-serializer:5.3.0")
    implementation("org.apache.avro:avro:1.11.0")
    annotationProcessor 'org.springframework.boot:spring-boot-configuration-processor'
    testImplementation 'org.springframework.boot:spring-boot-starter-test'
    testImplementation 'org.springframework.boot:spring-boot-testcontainers'
    testImplementation 'org.springframework.cloud:spring-cloud-stream-test-binder'
    testImplementation 'org.testcontainers:junit-jupiter'
    testImplementation 'org.testcontainers:kafka'
}

dependencyManagement {
    imports {
        mavenBom "org.springframework.cloud:spring-cloud-dependencies:${springCloudVersion}"
    }
}

schemaRegistry {
    url = 'http://localhost:8081'
    quiet = true
}

tasks.withType(KotlinCompile) {
    kotlinOptions {
        freeCompilerArgs += '-Xjsr305=strict'
        jvmTarget = '17'
    }
}

tasks.named('test') {
    useJUnitPlatform()
}
```

## Starting the application:
1. Start Docker containers with the following command from the root dir:
```shell
docker-compose up -d
```
There are 5 containers:
- Zookeper
- Kafka
- Schema Registry
- Postgres (for kadeck)
- kadeck (UI tool to monitor Kafka topics and Schema registry) available at http://localhost:80

2. When all containers are up, register AVRO schema with the following command from reviewproducer dir:
```shell
 ./gradlew registerSchemasTask 
```
This is a Gradle Task, executed by Gradle plugin `id "com.github.imflog.kafka-schema-registry-gradle-plugin" version "1.6.0"`.
Here is the configuration of the schemaRegistry task in gradle:
```groovy
schemaRegistry {
    url = 'http://localhost:8081'
    quiet = true
    register {
        subject('avro-reviewplaced-value', 'src/main/avro/review-placed.avsc', 'AVRO')
    }
}
```
3. After successfully registering the schema, run both Review Producer and Review Consumer applications on your
local machine. 
4. Now you can send an HTTP POST request to http://localhost:9000/reviews/v1
You can use Postman to send requests. Example postman collection with single POST request is in
postman directory. 

